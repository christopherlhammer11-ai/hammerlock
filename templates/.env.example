# VaultAI environment template
# Copy to .env.local and adjust before running the CLI

DATABASE_URL="file:./dev.db"
VAULT_PATH="./vault.json"

# Local LLM (tried first — install Ollama from https://ollama.ai then run: ollama pull phi3)
OLLAMA_BASE_URL="http://localhost:11434"
OLLAMA_MODEL="phi3"

# Cloud providers (optional — used as fallback when Ollama is unavailable)
OPENAI_API_KEY=""
ANTHROPIC_API_KEY=""

# Web search
BRAVE_API_KEY=""
